{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad1f8d3-2249-48dd-91c9-c455298810bc",
   "metadata": {},
   "source": [
    "## Open-field backward locomotion analysis (DLC-based)\n",
    "\n",
    "This notebook analyzes DeepLabCut tracking data to classify locomotion direction (forward, backward, leftward, rightward) on a frame-by-frame basis.\n",
    "\n",
    "Movement direction is computed from the angle between the movement vector (Back displacement) and the body-axis vector (Tailbaseâ†’Back), with a speed threshold applied to exclude low-motion frames.\n",
    "\n",
    "Peri-stimulus movement proportions are calculated in fixed time bins and used for linear mixed-effects modeling across mice and trials.\n",
    "\n",
    "Expected input location: data/raw/     \n",
    "##  .h5 tracking files and stimulus timestamp files are required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8fdbe-3fa4-4fab-99b6-cadb141d4cdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Set the directory where your DLC H5 data files are located\n",
    "data_directory = r'data/raw/'\n",
    "\n",
    "# Parameters\n",
    "sampling_rate = 30  # frames per second\n",
    "bin_size_frames = 6  # Number of frames per bin (200 ms per bin)\n",
    "pre_stim_frames = 30   # Frames before stimulus to analyze (1 second)\n",
    "post_stim_frames = 120  # Frames after stimulus to analyze (4 seconds)\n",
    "\n",
    "# Convert frames to time (seconds)\n",
    "bin_size_time = bin_size_frames / sampling_rate  # Bin size in seconds\n",
    "pre_stim_time = pre_stim_frames / sampling_rate  # Pre-stimulus time in seconds\n",
    "post_stim_time = post_stim_frames / sampling_rate  # Post-stimulus time in seconds\n",
    "\n",
    "# Angle thresholds\n",
    "forward_threshold = 60\n",
    "backward_threshold = 120\n",
    "\n",
    "# Speed threshold\n",
    "speed_threshold = 0.2  # Adjust as appropriate\n",
    "\n",
    "# List to store data from all animals\n",
    "all_data = []\n",
    "\n",
    "# Loop over animals (MouseID from 1 to 8)\n",
    "for mouse_id in range(1, 9):\n",
    "    # Define file paths\n",
    "    h5_file = os.path.join(data_directory, f'{mouse_id}.h5')\n",
    "    stim_file = os.path.join(data_directory, f'stim_{mouse_id}.csv')\n",
    "    \n",
    "    # Check if files exist\n",
    "    if not os.path.isfile(h5_file) or not os.path.isfile(stim_file):\n",
    "        print(f'Files for MouseID {mouse_id} not found.')\n",
    "        continue\n",
    "    \n",
    "    print(f'Processing data for MouseID {mouse_id}...')\n",
    "    \n",
    "    # Load the H5 file\n",
    "    try:\n",
    "        data = pd.read_hdf(h5_file)\n",
    "    except Exception as e:\n",
    "        print(f'Error loading {h5_file}: {e}')\n",
    "        continue\n",
    "    \n",
    "    # Load the stimulus times\n",
    "    try:\n",
    "        stimulus_times = pd.read_csv(stim_file)\n",
    "        stimulus_frames = stimulus_times.iloc[:, 0].values\n",
    "    except Exception as e:\n",
    "        print(f'Error loading {stim_file}: {e}')\n",
    "        continue\n",
    "    \n",
    "    # Extract coordinates for head, back, and tailbase\n",
    "    # Adjust the keys according to your data structure\n",
    "    try:\n",
    "        scorer = data.columns.levels[0][0]\n",
    "        back_x = data[scorer]['Back']['x'].values\n",
    "        back_y = data[scorer]['Back']['y'].values\n",
    "        tailbase_x = data[scorer]['Tailbase']['x'].values\n",
    "        tailbase_y = data[scorer]['Tailbase']['y'].values\n",
    "    except KeyError as e:\n",
    "        print(f'Error accessing body part coordinates for MouseID {mouse_id}: {e}')\n",
    "        continue\n",
    "    \n",
    "    # Apply smoothing to positional data (e.g., moving average filter)\n",
    "    window_size = 6  # Adjust window size as needed\n",
    "    def moving_average(a, n=window_size):\n",
    "        return np.convolve(a, np.ones(n)/n, mode='same')\n",
    "    \n",
    "    # Smooth the positional data\n",
    "    back_x_smooth = moving_average(back_x)\n",
    "    back_y_smooth = moving_average(back_y)\n",
    "    tailbase_x_smooth = moving_average(tailbase_x)\n",
    "    tailbase_y_smooth = moving_average(tailbase_y)\n",
    "    \n",
    "    # Calculate movement vectors using the smoothed 'Back' point\n",
    "    mv_x = back_x_smooth[1:] - back_x_smooth[:-1]\n",
    "    mv_y = back_y_smooth[1:] - back_y_smooth[:-1]\n",
    "    movement_vectors = np.stack((mv_x, mv_y), axis=-1)\n",
    "    \n",
    "    # Calculate movement magnitude (speed)\n",
    "    movement_magnitude = np.linalg.norm(movement_vectors, axis=1)\n",
    "    \n",
    "    # Set a speed threshold to exclude insignificant movements\n",
    "    significant_movement = movement_magnitude >= speed_threshold\n",
    "    \n",
    "    # Calculate orientation vectors from 'Tailbase' to 'Back' using smoothed data\n",
    "    ov_x = back_x_smooth[:-1] - tailbase_x_smooth[:-1]\n",
    "    ov_y = back_y_smooth[:-1] - tailbase_y_smooth[:-1]\n",
    "    orientation_vectors = np.stack((ov_x, ov_y), axis=-1)\n",
    "    \n",
    "    # Calculate dot products\n",
    "    dot_products = np.einsum('ij,ij->i', movement_vectors, orientation_vectors)\n",
    "    \n",
    "    # Calculate the angle between movement and orientation vectors\n",
    "    mv_norm = np.linalg.norm(movement_vectors, axis=1)\n",
    "    ov_norm = np.linalg.norm(orientation_vectors, axis=1)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    mv_norm[mv_norm == 0] = np.nan\n",
    "    ov_norm[ov_norm == 0] = np.nan\n",
    "    \n",
    "    cos_theta = dot_products / (mv_norm * ov_norm)\n",
    "    # Ensure cos_theta values are within valid range\n",
    "    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "    angles_rad = np.arccos(cos_theta)  # Angle in radians\n",
    "    angles_deg = np.degrees(angles_rad)  # Angle in degrees\n",
    "    \n",
    "    # Calculate cross product to determine left vs. right\n",
    "    # Since we are in 2D, we'll compute the z-component of the cross product manually\n",
    "    cross_products_z = movement_vectors[:, 0] * orientation_vectors[:, 1] - movement_vectors[:, 1] * orientation_vectors[:, 0]\n",
    "    \n",
    "    # Define movement categories\n",
    "    # Backward movement\n",
    "    backward_movement = (angles_deg > backward_threshold) & significant_movement\n",
    "    \n",
    "    # Forward movement\n",
    "    forward_movement = (angles_deg < forward_threshold) & significant_movement\n",
    "    \n",
    "    # Sideways movement (angles between 60 and 120 degrees)\n",
    "    sideways_movement = (angles_deg >= forward_threshold) & (angles_deg <= backward_threshold) & significant_movement\n",
    "    \n",
    "    # Leftward movement\n",
    "    leftward_movement = sideways_movement & (cross_products_z > 0)\n",
    "    \n",
    "    # Rightward movement\n",
    "    rightward_movement = sideways_movement & (cross_products_z < 0)\n",
    "    \n",
    "    # Initialize bins for PSTH\n",
    "    num_bins = int(np.ceil((pre_stim_frames + post_stim_frames) / bin_size_frames))\n",
    "    bin_edges_frames = np.arange(-pre_stim_frames, post_stim_frames + 1, bin_size_frames)  # Define edges explicitly\n",
    "    bin_edges_time = bin_edges_frames / sampling_rate  # Convert bin edges to seconds\n",
    "    time_points = bin_edges_time[1:]  # Time points now represent the end of each bin\n",
    "\n",
    "    \n",
    "    # For each stimulus, calculate movement proportions around it\n",
    "    for trial_id, stim_frame in enumerate(stimulus_frames):\n",
    "        # Determine frame range for peri-stimulus period\n",
    "        start_frame = stim_frame - pre_stim_frames\n",
    "        end_frame = stim_frame + post_stim_frames\n",
    "        # Adjust for edges\n",
    "        peri_start = max(start_frame, 0)\n",
    "        peri_end = min(end_frame, len(backward_movement))\n",
    "        # Extract peri-stimulus movement data\n",
    "        time_indices = np.arange(peri_start, peri_end)\n",
    "        times = (time_indices - stim_frame) / sampling_rate  # Time relative to stimulus\n",
    "        # Ensure times and movement data align\n",
    "        backward_data = backward_movement[peri_start:peri_end]\n",
    "        forward_data = forward_movement[peri_start:peri_end]\n",
    "        leftward_data = leftward_movement[peri_start:peri_end]\n",
    "        rightward_data = rightward_movement[peri_start:peri_end]\n",
    "        times = times[:len(backward_data)]\n",
    "        \n",
    "        # For each time bin, calculate movement proportions\n",
    "        for bin_idx in range(num_bins):\n",
    "            bin_start_time = -pre_stim_time + bin_idx * bin_size_time\n",
    "            bin_end_time = bin_start_time + bin_size_time\n",
    "            # Indices of times within the current bin\n",
    "            bin_indices = (times >= bin_start_time) & (times < bin_end_time)\n",
    "            if np.any(bin_indices):\n",
    "                # Calculate proportions for each movement type\n",
    "                proportion_backward = np.nanmean(backward_data[bin_indices])\n",
    "                proportion_forward = np.nanmean(forward_data[bin_indices])\n",
    "                proportion_leftward = np.nanmean(leftward_data[bin_indices])\n",
    "                proportion_rightward = np.nanmean(rightward_data[bin_indices])\n",
    "                # Create DataFrame rows for each movement type\n",
    "                for movement_type, proportion in zip(\n",
    "                    ['Backward', 'Forward', 'Leftward', 'Rightward'],\n",
    "                    [proportion_backward, proportion_forward, proportion_leftward, proportion_rightward]):\n",
    "                    data_row = {\n",
    "                        'MouseID': mouse_id,\n",
    "                        'TrialID': trial_id,\n",
    "                        'Time': bin_end_time,  # end of the bin\n",
    "                        'Proportion': proportion,\n",
    "                        'MovementType': movement_type\n",
    "                    }\n",
    "                    all_data.append(data_row)\n",
    "            else:\n",
    "                # No data in this bin (could happen at the edges)\n",
    "                continue\n",
    "    \n",
    "    print(f'Finished processing MouseID {mouse_id}.')\n",
    "    # Check if data was collected for this mouse\n",
    "    mouse_data = [d for d in all_data if d['MouseID'] == mouse_id]\n",
    "    if not mouse_data:\n",
    "        print(f'No data collected for MouseID {mouse_id}.')\n",
    "    else:\n",
    "        print(f'Data collected for MouseID {mouse_id}, number of observations: {len(mouse_data)}')\n",
    "\n",
    "print('Data processing complete.')\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df_all = pd.DataFrame(all_data)\n",
    "\n",
    "# Check which MouseIDs are included\n",
    "print('MouseIDs included in df_all:', df_all['MouseID'].unique())\n",
    "\n",
    "# Data preprocessing\n",
    "df_all['Time'] = df_all['Time'].astype(float)\n",
    "df_all['MouseID'] = df_all['MouseID'].astype('category')\n",
    "df_all['TrialID'] = df_all['TrialID'].astype('category')\n",
    "df_all['MovementType'] = df_all['MovementType'].astype('category')\n",
    "\n",
    "# Drop rows with NaN values in 'Proportion'\n",
    "df_all = df_all.dropna(subset=['Proportion'])\n",
    "\n",
    "# Create Time_bin with individual time bins (for plotting)\n",
    "df_all['Time_bin'] = df_all['Time'].apply(lambda x: f'{x:.1f}')\n",
    "\n",
    "# Create Time_bin_LMM for the LMM analysis (combine pre-stimulus bins)\n",
    "df_all['Time_bin_LMM'] = df_all['Time'].apply(lambda x: 'PreStimulus' if x < 0 else f'Post_{x:.1f}')\n",
    "\n",
    "# For the LMM, define categories with 'PreStimulus' as the reference\n",
    "unique_time_bins_LMM = df_all['Time_bin_LMM'].unique()\n",
    "time_bins_without_prestim = [tb for tb in unique_time_bins_LMM if tb != 'PreStimulus']\n",
    "categories_LMM = ['PreStimulus'] + sorted(time_bins_without_prestim, key=lambda x: float(x.replace('Post_', '')))\n",
    "\n",
    "df_all['Time_bin_LMM'] = pd.Categorical(df_all['Time_bin_LMM'], categories=categories_LMM, ordered=True)\n",
    "\n",
    "# For plotting, convert Time_bin to numeric values\n",
    "df_all['Time_numeric'] = df_all['Time']\n",
    "\n",
    "# Fit the LMM using Time_bin_LMM and MovementType with interaction\n",
    "print('Fitting Linear Mixed-Effects Model...')\n",
    "model = smf.mixedlm(\"Proportion ~ Time_bin_LMM * MovementType\", df_all, groups=df_all[\"MouseID\"])\n",
    "result = model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "# Add predicted values to df_all\n",
    "df_all['Predicted'] = result.predict()\n",
    "\n",
    "# Aggregate data for plotting (using individual time bins)\n",
    "agg_data = df_all.groupby(['Time', 'MovementType']).agg(\n",
    "    Mean_Proportion=('Proportion', 'mean'),\n",
    "    SEM_Proportion=('Proportion', 'sem'),\n",
    "    Mean_Predicted=('Predicted', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Sort the DataFrame by Time for proper plotting\n",
    "agg_data = agg_data.sort_values('Time')\n",
    "\n",
    "# Save the aggregated data to a CSV file\n",
    "output_csv = os.path.join(data_directory, 'aggregated_data_movement_types.csv')\n",
    "agg_data.to_csv(output_csv, index=False)\n",
    "print(f'Aggregated data saved to {output_csv}')\n",
    "\n",
    "# Plot Mean Proportion with SEM Shaded Area for each MovementType\n",
    "plt.figure(figsize=(12, 8))\n",
    "movement_types = df_all['MovementType'].unique()\n",
    "colors = {'Backward': 'blue', 'Forward': 'green', 'Leftward': 'orange', 'Rightward': 'purple'}\n",
    "\n",
    "for movement_type in movement_types:\n",
    "    data_subset = agg_data[agg_data['MovementType'] == movement_type]\n",
    "    plt.plot(data_subset['Time'], data_subset['Mean_Proportion'], label=f'{movement_type}', color=colors[movement_type])\n",
    "    plt.fill_between(data_subset['Time'],\n",
    "                     data_subset['Mean_Proportion'] - data_subset['SEM_Proportion'],\n",
    "                     data_subset['Mean_Proportion'] + data_subset['SEM_Proportion'],\n",
    "                     color=colors[movement_type], alpha=0.2)\n",
    "plt.axvline(0, color='k', linestyle='--', label='Stimulus Onset')\n",
    "plt.xlabel('Time from Stimulus (s)')\n",
    "plt.ylabel('Proportion of Movement')\n",
    "plt.title('Mean Proportion of Movement Types Over Time with SEM')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbc9af-cd18-4281-a12b-9e1ac10066e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
